{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alpha - NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from rag_pipeline import create_simple_retriever, load_questions_and_answers_from_opensearch\n",
    "from utils import create_opensearch_client\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ng(I, alpha, r):\n",
    "    \"\"\"\n",
    "    Compute the novelty-biased gain at r ng(r) as defined in https://link.springer.com/referenceworkentry/10.1007/978-1-4899-7993-3_80619-1.\n",
    "    \n",
    "    Parameters:\n",
    "    - I: A 2D list or array where I[i][r] = I_i(r) is the relevance of the document at rank r for intent i.\n",
    "    - alpha: The parameter alpha to be used in the computation.\n",
    "    - r: The rank at which ng(r) is to be computed.\n",
    "    \n",
    "    Returns:\n",
    "    - ng_r: The computed ng(r) value.\n",
    "    \"\"\"\n",
    "    ng_r = 0\n",
    "    for i in range(len(I)):  # Iterate over all intents\n",
    "        if r > 0:\n",
    "            C_i_r_minus_1 = np.sum(I[i][:r])  # C_i(r-1) is the sum of relevance scores up to rank r-1\n",
    "            ng_r += I[i][r-1] * (1 - alpha)**C_i_r_minus_1\n",
    "    \n",
    "    return ng_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "opensearch_user = os.getenv('OPENSEARCH_USER')\n",
    "opensearch_password = os.getenv('OPENSEARCH_PASSWORD')\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_text_with_openai(texts, model=\"text-embedding-3-small\"):\n",
    "    embeddings = []\n",
    "    for text in texts:\n",
    "        embeddings.append(client.embeddings.create(input = [text], model=model).data[0].embedding)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_matrix(intents_embeddings, docs_embeddings, threshold):\n",
    "    # Initialize the matrix I with zeros (intents x docs)\n",
    "    num_intents = len(intents_embeddings)\n",
    "    num_docs = len(docs_embeddings)\n",
    "    I = np.zeros((num_intents, num_docs))\n",
    "\n",
    "    # Loop over each intent and document, compute cosine similarity, and apply threshold\n",
    "    for i, intent_embedding in enumerate(intents_embeddings):\n",
    "        for j, doc_embedding in enumerate(docs_embeddings):\n",
    "            similarity = cosine_similarity([intent_embedding], [doc_embedding])[0][0]\n",
    "            if similarity >= threshold:\n",
    "                I[i, j] = 1\n",
    "\n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_alpha_ndcg(ng, k):\n",
    "    # sum up ng(r) / log_2(r+1) for r = 1 to k\n",
    "    alpha_ndcg = 0\n",
    "    for r in range(1, k+1):\n",
    "        alpha_ndcg += ng[r-1] / np.log2(r+1)\n",
    "    return alpha_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opensearch_client = create_opensearch_client(username=opensearch_user, password=opensearch_password)\n",
    "opensearch_url = \"https://opensearch-ds-2.ifi.uni-heidelberg.de:443\"\n",
    "\n",
    "kb_index_name = \"eur-lex-diversified-knowledge-base-3\"\n",
    "qa_index_name = \"eur-lex-diversified-qa-askep\"\n",
    "k = 10\n",
    "nr_questions = 1000\n",
    "threshold = 0.5\n",
    "alpha = 0.5\n",
    "alpha_ndcg_scores = []\n",
    "\n",
    "# create retriever\n",
    "simple_retriever = create_simple_retriever(kb_index_name, opensearch_url, k=k)\n",
    "# load questions and answers\n",
    "questions_and_answers = load_questions_and_answers_from_opensearch(qa_index_name, opensearch_client, size=nr_questions)\n",
    "# extract the keys from the each answer\n",
    "for i, (question, ground_truth_answer) in enumerate(questions_and_answers):\n",
    "    # use the section titles as intents\n",
    "    intents = list(ground_truth_answer.keys())\n",
    "    # embed section titles\n",
    "    intents_embeddings = embed_text_with_openai(intents)\n",
    "    # retrieve the top k documents\n",
    "    docs = simple_retriever.invoke(question)\n",
    "    # embed the documents\n",
    "    doc_embeddings = embed_text_with_openai([doc.page_content for doc in docs])\n",
    "    # compute the similarity matrix\n",
    "    I = compute_similarity_matrix(intents_embeddings, doc_embeddings, threshold=threshold)\n",
    "    # compute ng for each rank r\n",
    "    ng = np.zeros(k)\n",
    "    for r in range(k):\n",
    "        ng[r] = compute_ng(I, alpha, r)\n",
    "    # compute alpha-ndcg\n",
    "    alpha_ndcg = compute_alpha_ndcg(ng, k)\n",
    "    alpha_ndcg_scores.append(alpha_ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_ndcg_scores"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_homework",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
